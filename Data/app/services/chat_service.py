import os
import json
import requests
from typing import List
from sqlalchemy.orm import Session
from sentence_transformers import SentenceTransformer

from app.models import UserSetting
from app.utils.es import get_es
from app.adapters.redis_io import append_conversation  # í‘œì¤€: (room_id, role, content)

# ===============================
# ENV / ìƒìˆ˜
# ===============================
REDIS_TTL_SEC = int(os.getenv("REDIS_TTL_SEC", "3600"))  # ìœ ì§€: ë‹¤ë¥¸ ë ˆì´ì–´ì—ì„œ TTL ì‚¬ìš© ì‹œ ì°¸ê³ 
EMBED_MODEL_PATH = os.getenv("EMBED_MODEL_PATH", "/app/models/embedding")
USER_MEMORY_EMBED_INDEX = os.getenv("USER_MEMORY_EMBED_INDEX", "user_memory_embedding")

GMS_API_KEY = os.getenv("GMS_API_KEY")
GMS_API_URL = os.getenv("GMS_API_URL")
GMS_MODEL_NAME = os.getenv("GMS_MODEL_NAME", "gpt-4o-mini")
GMS_TIMEOUT = float(os.getenv("GMS_TIMEOUT_SEC", "30"))

KNN_TOP_K = int(os.getenv("KNN_TOP_K", "3"))
KNN_MIN_SCORE = float(os.getenv("KNN_MIN_SCORE", "0.7"))
KNN_NUM_CANDIDATES = int(os.getenv("KNN_NUM_CANDIDATES", "100"))

# ===============================
# ì„ë² ë”© ëª¨ë¸ (ì§€ì—° ë¡œë”©)
# ===============================
_embedder = None
def get_embedder() -> SentenceTransformer:
    global _embedder
    if _embedder is None:
        _embedder = SentenceTransformer(EMBED_MODEL_PATH)
    return _embedder

# ===============================
# System Prompt ìƒì„±
# ===============================
def build_system_prompt(session: Session, user_id: str) -> str:
    setting = session.query(UserSetting).filter(UserSetting.user_id == user_id).first()
    if not setting:
        return "You are a helpful assistant that replies in Korean.\n- ë‹µë³€ì€ ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."

    tone_map = {
        "NEUTRAL": "ì¼ë°˜ì ì¸ AI ìŠ¤íƒ€ì¼ ğŸ§ ",
        "FRIENDLY": "ë‹¤ì •í•˜ê³  ë”°ëœ»í•œ ëŠë‚Œ, ì´ëª¨ì§€ë„ ì‚¬ìš© ğŸ˜Š",
        "POLITE": "ê³µì†í•˜ê³  ê²©ì‹ ìˆëŠ” ì¡´ëŒ“ë§ ìœ„ì£¼ ğŸ’¼",
        "CHEERFUL": "í™œê¸°ì°¨ê³  ëª…ë‘í•œ ë§íˆ¬, ê°€ë²¼ìš´ ë†ë‹´ë„ ê°€ëŠ¥ ğŸ˜„",
        "CYNICAL": "ëƒ‰ì†Œì ì´ê³  ê¹Œì¹ í•œ ë§íˆ¬",
        "CALM": "ì¹¨ì°©í•˜ê³  ë‹´ë°±í•œ í‘œí˜„, ê°ì • í‘œí˜„ ìµœì†Œ ğŸŒ™",
    }

    parts = ["You are a Korean AI assistant.", "ë‹µë³€ì€ ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."]
    if setting.call_me:
        parts.append(f'ì‚¬ìš©ìë¥¼ "{setting.call_me}"ì´ë¼ê³  ë¶€ë¥´ì„¸ìš”.')
    if setting.role_description:
        parts.append(f"ì—­í• : {setting.role_description}")
    if setting.preferred_tone:
        tone_desc = tone_map.get(setting.preferred_tone, "")
        parts.append(f"ì‘ë‹µ í†¤: {setting.preferred_tone} ({tone_desc})")
    if setting.traits:
        parts.append(f"ì„±ê²©/íŠ¹ì§•: {setting.traits}")
    if setting.additional_context:
        parts.append(f"ì¶”ê°€ ë§¥ë½: {setting.additional_context}")

    return "\n- ".join(parts)

# ===============================
# ES ìœ ì‚¬ ë§¥ë½ ê²€ìƒ‰ (KNN + ì‚¬ìš©ì í•„í„°)
# ===============================
def _safe_join_lines(lines: List) -> str:
    out = []
    for x in (lines or []):
        if isinstance(x, str):
            out.append(x)
        else:
            out.append(json.dumps(x, ensure_ascii=False))
    return "\n".join(out)

def search_similar_context_es(query: str, user_id: str, top_k: int = KNN_TOP_K, min_score: float = KNN_MIN_SCORE):
    es = get_es()
    emb = get_embedder().encode(query).tolist()

    # ES 8.x/OpenSearchì˜ KNN ê²€ìƒ‰ì€ filterë¥¼ í•¨ê»˜ ì¤„ ìˆ˜ ìˆìŒ
    body = {
        "knn": {
            "field": "embedding",
            "query_vector": emb,
            "k": top_k,
            "num_candidates": KNN_NUM_CANDIDATES,
            "filter": {
                "term": { "user_seq": user_id }   # ì¸ë±ìŠ¤ì˜ í•„ë“œëª…ì´ user_seqì¸ ê²½ìš°
            }
        },
        "_source": ["content", "user_seq", "trace_id", "created_at"]
    }

    resp = es.search(index=USER_MEMORY_EMBED_INDEX, body=body)
    hits = resp.get("hits", {}).get("hits", []) or []

    results = []
    for h in hits:
        score = h.get("_score", 0.0)
        if score is None or score < min_score:
            continue
        src = h.get("_source") or {}
        content = src.get("content")
        if content:
            results.append(content)
    return results

# ===============================
# GPT í˜¸ì¶œ + Redis ì €ì¥
# ===============================
def process_user_message(session: Session, payload):
    """
    1) System prompt ë¶ˆëŸ¬ì˜¤ê¸°
    2) Redis ìµœê·¼ ëŒ€í™” ë¡œë“œ (adapters.redis_ioì—ì„œ turn ë‹¨ìœ„ ì €ì¥/ë¡œë“œ ì‚¬ìš© ê¶Œì¥)
    3) ES ìœ ì‚¬ ë§¥ë½ ê²€ìƒ‰ (ë™ì¼ ì‚¬ìš©ì í•„í„°)
    4) GMS API í˜¸ì¶œ
    5) Redis ì €ì¥ (user/assistant ê° 1í„´ì”©)
    """
    if not GMS_API_URL or not GMS_API_KEY:
        raise RuntimeError("GMS_API_URL/GMS_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    # 1. System prompt
    system_prompt = build_system_prompt(session, payload.user_id)

    # 2. Redis ìµœê·¼ ëŒ€í™”: adapters.redis_io ìª½ì˜ getterë¥¼ ì“°ëŠ” ê²ƒì´ ì´ìƒì ì´ì§€ë§Œ,
    #    ì—¬ê¸°ì„œëŠ” ìµœì†Œ ë©”ì‹œì§€ í¬ê¸°ë¥¼ ìœ„í•´ ìµœê·¼ Ní„´ë§Œ ë¶ˆëŸ¬ì˜¨ë‹¤ê³  ê°€ì •.
    #    get_conversation(room_id, limit) í˜•íƒœì˜ ìœ í‹¸ì´ ìˆë‹¤ë©´ ê·¸ê±¸ ì“°ëŠ” ê²ƒì„ ê¶Œì¥.
    try:
        from app.adapters.redis_io import get_conversation  # í‘œì¤€ ì‹œê·¸ë‹ˆì²˜ ê°€ì •: (room_id, limit)
        history = get_conversation(payload.room_id, limit=5) or []
    except Exception:
        # ì•ˆì „ë§: íˆìŠ¤í† ë¦¬ë¥¼ ë¹„ì›Œì„œ ì§„í–‰
        history = []

    # 3. ES ìœ ì‚¬ ë§¥ë½ (ë™ì¼ ì‚¬ìš©ì í•„í„°)
    similar_contexts = []
    try:
        similar_contexts = search_similar_context_es(payload.text, user_id=payload.user_id, top_k=KNN_TOP_K)
    except Exception:
        # ES ì¥ì•  ì‹œì—ë„ ë³¸ ë¡œì§ì€ ì§„í–‰
        similar_contexts = []

    # 4. ìµœì¢… ë©”ì‹œì§€ êµ¬ì„± (OpenAI ìŠ¤íƒ€ì¼)
    messages = [{"role": "system", "content": system_prompt}]
    for h in history:
        # hëŠ” {"role": "...", "content": "..."} í¬ë§·ì´ë¼ê³  ê°€ì •
        role = h.get("role")
        content = h.get("content")
        if role and content:
            messages.append({"role": role, "content": content})

    if similar_contexts:
        context_str = _safe_join_lines(similar_contexts)
        messages.append({"role": "system", "content": f"ì°¸ê³ í•  ì¶”ê°€ ë§¥ë½:\n{context_str}"})

    messages.append({"role": "user", "content": payload.text})

    # 5. GMS API í˜¸ì¶œ
    headers = {"Authorization": f"Bearer {GMS_API_KEY}"}
    req_json = {"model": GMS_MODEL_NAME, "messages": messages}

    try:
        response = requests.post(GMS_API_URL, headers=headers, json=req_json, timeout=GMS_TIMEOUT)
        response.raise_for_status()
        j = response.json()
        assistant_output = j["choices"][0]["message"]["content"]
    except (requests.RequestException, KeyError, IndexError) as e:
        raise Exception(f"GMS API error: {getattr(e, 'response', None) and getattr(e.response, 'text', '') or str(e)}")

    # 6. Redisì— ì €ì¥ (í„´ ë¶„ë¦¬: user â†’ assistant)
    append_conversation(payload.room_id, "user", payload.text)
    append_conversation(payload.room_id, "assistant", assistant_output)

    return assistant_output
